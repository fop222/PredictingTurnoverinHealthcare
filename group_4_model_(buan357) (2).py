# -*- coding: utf-8 -*-
"""Group #4 Model (BUAN357)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fs7mHFfGlG_mvQxD8_D_CgjvsCcsOFkc

# Data Loading
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder

logr = LogisticRegression()
dtree = DecisionTreeClassifier()
rforest = RandomForestClassifier()
gradboost = GradientBoostingClassifier()

df = pd.read_csv("/content/Healthcare Workforce Mental Health Dataset.csv")
df.head()

# preview dataset shape (rows, columns)
print("Shape of original data:", df.shape)

# display column names
print("\nColumns in dataset:")
print(df.columns)

"""# Data Pre-processing"""

# drop unique identifier that should not be used as a predictor
# (Employee ID is just an ID, not a meaningful feature)
df = df.drop(columns=['Employee ID'])

# convert categorical features into dummy (0/1)  variables
df2 = pd.get_dummies(
    df,
    columns=[
        'Employee Type',
        'Department',
        'Workplace Factor',
        'Access to EAPs',
        'Burnout Frequency',
        'Turnover Intention'
    ],
    dtype=int
)

#display variables
print("\nPreview after get_dummies:")
print(df2.head())

# display columns after one-hot encoding
print("\nColumns after get_dummies:")
print(df2.columns)

# drop rows with any missing values from the DataFrame
df2 = df2.dropna()

# create a copy of the preprocessed DataFrame for EDA
df_processed = df2.copy()

"""# Exploratory Data Analysis"""

# generate a correlation heatmap for key features of interest
import seaborn as sns
import matplotlib.pyplot as plt

cols_of_interest = [
    'Stress Level',
    'Job Satisfaction',
    'Mental Health Absences',
    'Turnover Intention_Yes',
    'Burnout Frequency_Often',
    'Access to EAPs_Yes'
]

corr = df_processed[cols_of_interest].corr()

# Set plot size
plt.figure(figsize=(16,14)) # Increased size due to more columns after one-hot encoding

# Draw heatmap
sns.heatmap(corr,
            annot=False,          # Set to False due to large number of columns after encoding
            cmap='coolwarm',      # red–blue color scheme
            vmin=-1, vmax=1,      # full correlation scale
            linewidths=0.3,       # thin lines between cells
            square=True,          # keep it square like your example
            fmt=".2f")            # number formatting

plt.title("Correlation Heatmap", fontsize=16, pad=15)
plt.tight_layout() # Adjust layout to prevent labels from overlapping
plt.show()

# create a pairplot for key mental health indicators
sns.pairplot(df_processed[['Stress Level','Job Satisfaction','Mental Health Absences']],
             corner=True)
plt.suptitle("Pairplot of Key Mental Health Indicators", y=1.02)
plt.show()

# visualize average stress level by workplace factor
df_processed['Workplace Factor'] = df['Workplace Factor']

plt.figure(figsize=(12,6))
df_processed.groupby('Workplace Factor')['Stress Level'] \
            .mean() \
            .sort_values() \
            .plot(kind='bar')

plt.title("Average Stress Level by Workplace Factor")
plt.ylabel("Average Stress Level (1–10)")
plt.show()

# plot turnover intention percentage by employee type
df_processed['Employee Type'] = df['Employee Type']
df_processed['Turnover Intention'] = df['Turnover Intention']


turnover_by_type = pd.crosstab(
    df_processed['Employee Type'],
    df_processed['Turnover Intention'],
    normalize='index'
) * 100

turnover_by_type.plot(kind='bar', figsize=(10,5))
plt.title("Turnover Intention (%) by Employee Type")
plt.ylabel("Percent")
plt.show()

# analyze turnover intention based on access to EAPs
df_processed['Access to EAPs'] = df['Access to EAPs']
df_processed['Turnover Intention'] = df['Turnover Intention']


eap_pivot = pd.crosstab(
    df_processed['Access to EAPs'],
    df_processed['Turnover Intention'],
    normalize='index'
) * 100

eap_pivot.plot(kind='bar', figsize=(10,5))
plt.title("Turnover Intention by EAP Access")
plt.ylabel("Percentage")
plt.show()

# show burnout frequency distribution across different departments
df_processed['Department'] = df['Department']
df_processed['Burnout Frequency'] = df['Burnout Frequency']

pivot_turnover_burnout = pd.crosstab(
    df_processed['Department'],
    df_processed['Burnout Frequency']
)

pivot_turnover_burnout.plot(
    kind='bar',
    stacked=True,
    figsize=(14,6)
)

plt.title("Burnout Frequency Distribution Across Departments")
plt.ylabel("Employee Count")
plt.xlabel("Department")
plt.show()

# calculate and visualize the average high burnout rate by department
df_processed['Department'] = df['Department']
df_processed['Burnout Frequency'] = df['Burnout Frequency']

df_processed['High_Burnout_Label'] = (df_processed['Burnout Frequency'] == 'Often').astype(int)

burnout_mean = df_processed.groupby('Department')['High_Burnout_Label'].mean().sort_values()

burnout_mean.plot(kind='bar', figsize=(12,5))
plt.title("Average High Burnout Rate by Department")
plt.ylabel("Proportion of Employees with High Burnout (Often=1)")
plt.xlabel("Department")
plt.show()

"""# Training & Testing"""

# define target variable (y) and features (X) for model training
y = df2['Turnover Intention_Yes']
X = df2.drop(columns=['Turnover Intention_Yes', 'Turnover Intention_No'])

# split data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)

# display data types of columns in df2
df2.dtypes

# train and evaluate multiple classification models
algos = [logr, dtree, gradboost, rforest]

results_df = pd.DataFrame()
names = []
accs = []
precisions = []
recalls = []
f1s = []

for model in algos:
    # train model
    model.fit(X_train, y_train)

    # predictions
    y_pred = model.predict(X_test)

    # store results
    names.append(type(model).__name__)
    accs.append(accuracy_score(y_test, y_pred))
    precisions.append(precision_score(y_test, y_pred))
    recalls.append(recall_score(y_test, y_pred))
    f1s.append(f1_score(y_test, y_pred))

# add results to dataframe
results_df['Model'] = names
results_df['Accuracy'] = accs
results_df['Precision'] = precisions
results_df['Recall'] = recalls
results_df['F1 Score'] = f1s

results_df

# Plot the results of the trained models
import matplotlib.pyplot as plt
import seaborn as sns

# Melt the DataFrame to long format for easier plotting with seaborn
results_melted = results_df.melt(id_vars='Model', var_name='Metric', value_name='Score')

plt.figure(figsize=(12, 7))
sns.barplot(x='Model', y='Score', hue='Metric', data=results_melted, palette='viridis')
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.ylim(0, 1) # Metrics are typically between 0 and 1
plt.xticks(rotation=45, ha='right') # Rotate model names for better readability
plt.legend(title='Metric')
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Get predicted probabilities (for class 1)
y_prob = model.predict_proba(X_test)[:, 1]

# Compute ROC-AUC
auc = roc_auc_score(y_test, y_prob)
print("ROC-AUC Score:", auc)

# perform Recursive Feature Elimination (RFE) to select top features
from sklearn.feature_selection import RFE

selector = RFE(rforest, n_features_to_select=20)  # Random Forest is good for feature selection
selector = selector.fit(X_train, y_train)

z = pd.DataFrame()
z['feature'] = X.columns
z['support'] = selector.support_
z['rank'] = selector.ranking_

top_features = z[z['support'] == True]
top_features

#bar graph of RFE results
rfe_results = pd.DataFrame({
    'feature': selector.feature_names_in_,
    'rank': selector.ranking_,
    'selected': selector.support_
})

rfe_results = rfe_results.sort_values('rank', ascending=True)

plt.figure(figsize=(10, 12))

sns.barplot(
    data=rfe_results,
    x='rank',
    y='feature',
    palette='viridis',
    orient='h',
    order=rfe_results['feature']  # ensures order stays sorted
)

plt.title("RFE Feature Ranking (Rank 1 = Most Important)")
plt.xlabel("RFE Rank (Lower = Least Important)")
plt.ylabel("Feature")
plt.tight_layout()
plt.show()